{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spherical Gaussian experiment (2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import logging\n",
    "\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "import manifold_flow as mf\n",
    "from manifold_flow import transforms, utils, distributions, training\n",
    "from manifold_flow.flows import Flow, ManifoldFlow\n",
    "from manifold_flow import nn as nn_\n",
    "from experiments.simulators.spherical_simulator import SphericalGaussianSimulator\n",
    "from experiments.utils import vector_transforms\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)-5.5s %(name)-30.30s %(levelname)-7.7s %(message)s\",\n",
    "    datefmt=\"%H:%M\",\n",
    "    level=logging.DEBUG,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "# Output of all other modules (e.g. matplotlib)\n",
    "for key in logging.Logger.manager.loggerDict:\n",
    "    if \"experiments\" not in key and \"manifold_flow\" not in key:\n",
    "        logging.getLogger(key).setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "n_train = 100000\n",
    "epsilon = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = SphericalGaussianSimulator(latent_dim=1, data_dim=2, epsilon=epsilon)\n",
    "x = simulator.sample(n_train)\n",
    "x_tensor = torch.from_numpy(x)\n",
    "train_dataset = TensorDataset(x_tensor, x_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:35 experiments.simulators.spheric DEBUG   Evaluating true log density for x = [-1.4 -1.4]\n",
      "21:35 experiments.simulators.spheric DEBUG   Latent variables: z_phi = [3.92699082], z_eps = [0.97989899]\n",
      "../../experiments/simulators/spherical_simulator.py:108: RuntimeWarning: divide by zero encountered in log\n",
      "  logp_eps = np.log(norm(loc=0.0, scale=self._epsilon).pdf(z_eps))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = 200\n",
    "x_range = np.linspace(-1.4,1.4,res)\n",
    "y_range = np.linspace(-1.4,1.4,res)\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "x_grid = np.concatenate((xx.reshape((-1,1)), yy.reshape((-1,1))), axis=1)\n",
    "logp_grid = simulator.log_density(x_grid, precise=True).reshape((res, res))\n",
    "logp_grid[~np.isfinite(logp_grid)] = -1000000.\n",
    "\n",
    "zmin, zmax = np.max(logp_grid) - 10, np.max(logp_grid)\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "ax = plt.gca()\n",
    "\n",
    "pcm = plt.imshow(\n",
    "    np.clip(logp_grid, zmin, zmax),\n",
    "    extent=(-1.4,1.4,-1.4,1.4),\n",
    "    origin=\"lower\",\n",
    "    cmap=\"viridis\", norm=matplotlib.colors.Normalize(zmin, zmax),\n",
    "    interpolation='nearest'\n",
    ")\n",
    "cb = plt.colorbar(pcm, extend=\"both\")\n",
    "plt.scatter(x[::50,0], x[::50,1], s=2., c=\"black\", alpha=1.)\n",
    "\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "cb.set_label(\"$\\log \\; p(x)$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"spherical_gaussian_2d_data.pdf\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000930850098504"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_size = (x_range[1] - x_range[0]) * (y_range[1] - y_range[0])\n",
    "\n",
    "np.sum(np.exp(logp_grid) * pixel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifold flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21:35 manifold_flow.transforms.proje DEBUG   Set up projection from vector with dimension 2 to vector with dimension 1\n",
      "21:35 manifold_flow.flows.base       DEBUG   Created standard flow with 0.0 M parameters (0.0 M trainable) with an estimated size of 0.0 <B\n",
      "21:35 manifold_flow.training.trainer INFO    Training on CPU with single precision\n",
      "21:35 manifold_flow.training.trainer DEBUG   Initialising training data\n",
      "21:35 manifold_flow.training.trainer DEBUG   Setting up optimizer\n",
      "21:35 manifold_flow.training.trainer DEBUG   Setting up LR scheduler\n",
      "21:35 manifold_flow.training.trainer DEBUG   Using early stopping with infinite patience\n",
      "21:35 manifold_flow.training.trainer DEBUG   Will print training progress every 1 epochs\n",
      "21:35 manifold_flow.training.trainer DEBUG   Beginning main training loop\n",
      "21:35 manifold_flow.training.trainer DEBUG   Training epoch 1 / 10\n",
      "21:35 manifold_flow.training.trainer DEBUG     Learning rate: [0.001]\n",
      "21:35 manifold_flow.training.trainer INFO    Epoch   1: train loss  5.14066 (mse:  0.051)\n",
      "21:35 manifold_flow.training.trainer INFO               val. loss   0.44787 (mse:  0.004)\n",
      "21:35 manifold_flow.training.trainer DEBUG   Training epoch 2 / 10\n",
      "21:35 manifold_flow.training.trainer DEBUG     Learning rate: [0.001]\n",
      "21:35 manifold_flow.training.trainer INFO    Epoch   2: train loss  0.28644 (mse:  0.003)\n",
      "21:35 manifold_flow.training.trainer INFO               val. loss   0.31097 (mse:  0.003)\n",
      "21:35 manifold_flow.training.trainer DEBUG   Training epoch 3 / 10\n",
      "21:35 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009755282581475768]\n",
      "21:35 manifold_flow.training.trainer INFO    Epoch   3: train loss  0.20803 (mse:  0.002)\n",
      "21:35 manifold_flow.training.trainer INFO               val. loss   0.24442 (mse:  0.002)\n",
      "21:35 manifold_flow.training.trainer DEBUG   Training epoch 4 / 10\n",
      "21:35 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009045084971874737]\n",
      "21:35 manifold_flow.training.trainer INFO    Epoch   4: train loss  0.16199 (mse:  0.002)\n",
      "21:35 manifold_flow.training.trainer INFO               val. loss   0.18408 (mse:  0.002)\n",
      "21:35 manifold_flow.training.trainer DEBUG   Training epoch 5 / 10\n",
      "21:35 manifold_flow.training.trainer DEBUG     Learning rate: [0.0007938926261462367]\n",
      "21:35 manifold_flow.training.trainer INFO    Epoch   5: train loss  0.12595 (mse:  0.001)\n",
      "21:35 manifold_flow.training.trainer INFO               val. loss   0.16217 (mse:  0.002)\n",
      "21:35 manifold_flow.training.trainer DEBUG   Training epoch 6 / 10\n",
      "21:35 manifold_flow.training.trainer DEBUG     Learning rate: [0.0006545084971874737]\n",
      "21:35 manifold_flow.training.trainer INFO    Epoch   6: train loss  0.11567 (mse:  0.001)\n",
      "21:35 manifold_flow.training.trainer INFO               val. loss   0.28786 (mse:  0.003)\n",
      "21:35 manifold_flow.training.trainer DEBUG   Training epoch 7 / 10\n",
      "21:35 manifold_flow.training.trainer DEBUG     Learning rate: [0.0005]\n",
      "21:36 manifold_flow.training.trainer INFO    Epoch   7: train loss  0.10636 (mse:  0.001)\n",
      "21:36 manifold_flow.training.trainer INFO               val. loss   0.16884 (mse:  0.002)\n",
      "21:36 manifold_flow.training.trainer DEBUG   Training epoch 8 / 10\n",
      "21:36 manifold_flow.training.trainer DEBUG     Learning rate: [0.00034549150281252633]\n",
      "21:36 manifold_flow.training.trainer INFO    Epoch   8: train loss  0.09923 (mse:  0.001)\n",
      "21:36 manifold_flow.training.trainer INFO               val. loss   0.13678 (mse:  0.001)\n",
      "21:36 manifold_flow.training.trainer DEBUG   Training epoch 9 / 10\n",
      "21:36 manifold_flow.training.trainer DEBUG     Learning rate: [0.00020610737385376348]\n",
      "21:36 manifold_flow.training.trainer INFO    Epoch   9: train loss  0.09454 (mse:  0.001)\n",
      "21:36 manifold_flow.training.trainer INFO               val. loss   0.13592 (mse:  0.001)\n",
      "21:36 manifold_flow.training.trainer DEBUG   Training epoch 10 / 10\n",
      "21:36 manifold_flow.training.trainer DEBUG     Learning rate: [9.549150281252633e-05]\n",
      "21:36 manifold_flow.training.trainer INFO    Epoch  10: train loss  0.09178 (mse:  0.001)\n",
      "21:36 manifold_flow.training.trainer INFO               val. loss   0.13454 (mse:  0.001)\n",
      "21:36 manifold_flow.training.trainer INFO    Early stopping did not improve performance\n",
      "21:36 manifold_flow.training.trainer DEBUG   Training finished\n",
      "21:36 manifold_flow.training.trainer DEBUG   Initialising training data\n",
      "21:36 manifold_flow.training.trainer DEBUG   Setting up optimizer\n",
      "21:36 manifold_flow.training.trainer DEBUG   Setting up LR scheduler\n",
      "21:36 manifold_flow.training.trainer DEBUG   Using early stopping with infinite patience\n",
      "21:36 manifold_flow.training.trainer DEBUG   Will print training progress every 1 epochs\n",
      "21:36 manifold_flow.training.trainer DEBUG   Beginning main training loop\n",
      "21:36 manifold_flow.training.trainer DEBUG   Training epoch 1 / 10\n",
      "21:36 manifold_flow.training.trainer DEBUG     Learning rate: [0.001]\n",
      "21:39 manifold_flow.training.trainer INFO    Epoch   1: train loss -1.01890 (mse:  0.001, nll: -1.019)\n",
      "21:39 manifold_flow.training.trainer INFO               val. loss  -1.15960 (mse:  0.001, nll: -1.160)\n",
      "21:39 manifold_flow.training.trainer DEBUG   Training epoch 2 / 10\n",
      "21:39 manifold_flow.training.trainer DEBUG     Learning rate: [0.001]\n",
      "21:42 manifold_flow.training.trainer INFO    Epoch   2: train loss -1.27706 (mse:  0.001, nll: -1.277)\n",
      "21:42 manifold_flow.training.trainer INFO               val. loss  -1.35305 (mse:  0.001, nll: -1.353)\n",
      "21:42 manifold_flow.training.trainer DEBUG   Training epoch 3 / 10\n",
      "21:42 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009755282581475768]\n",
      "21:46 manifold_flow.training.trainer INFO    Epoch   3: train loss -1.43040 (mse:  0.001, nll: -1.430)\n",
      "21:46 manifold_flow.training.trainer INFO               val. loss  -1.47291 (mse:  0.001, nll: -1.473)\n",
      "21:46 manifold_flow.training.trainer DEBUG   Training epoch 4 / 10\n",
      "21:46 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009045084971874737]\n",
      "21:49 manifold_flow.training.trainer INFO    Epoch   4: train loss -1.52635 (mse:  0.001, nll: -1.526)\n",
      "21:49 manifold_flow.training.trainer INFO               val. loss  -1.54816 (mse:  0.001, nll: -1.548)\n",
      "21:49 manifold_flow.training.trainer DEBUG   Training epoch 5 / 10\n",
      "21:49 manifold_flow.training.trainer DEBUG     Learning rate: [0.0007938926261462367]\n",
      "21:52 manifold_flow.training.trainer INFO    Epoch   5: train loss -1.58649 (mse:  0.001, nll: -1.586)\n",
      "21:52 manifold_flow.training.trainer INFO               val. loss  -1.59410 (mse:  0.001, nll: -1.594)\n",
      "21:52 manifold_flow.training.trainer DEBUG   Training epoch 6 / 10\n",
      "21:52 manifold_flow.training.trainer DEBUG     Learning rate: [0.0006545084971874737]\n",
      "21:56 manifold_flow.training.trainer INFO    Epoch   6: train loss -1.62288 (mse:  0.001, nll: -1.623)\n",
      "21:56 manifold_flow.training.trainer INFO               val. loss  -1.62136 (mse:  0.001, nll: -1.621)\n",
      "21:56 manifold_flow.training.trainer DEBUG   Training epoch 7 / 10\n",
      "21:56 manifold_flow.training.trainer DEBUG     Learning rate: [0.0005]\n",
      "21:59 manifold_flow.training.trainer INFO    Epoch   7: train loss -1.64413 (mse:  0.001, nll: -1.644)\n",
      "21:59 manifold_flow.training.trainer INFO               val. loss  -1.63674 (mse:  0.001, nll: -1.637)\n",
      "21:59 manifold_flow.training.trainer DEBUG   Training epoch 8 / 10\n",
      "21:59 manifold_flow.training.trainer DEBUG     Learning rate: [0.00034549150281252633]\n",
      "22:02 manifold_flow.training.trainer INFO    Epoch   8: train loss -1.65604 (mse:  0.001, nll: -1.656)\n",
      "22:02 manifold_flow.training.trainer INFO               val. loss  -1.64516 (mse:  0.001, nll: -1.645)\n",
      "22:02 manifold_flow.training.trainer DEBUG   Training epoch 9 / 10\n",
      "22:02 manifold_flow.training.trainer DEBUG     Learning rate: [0.00020610737385376348]\n",
      "22:05 manifold_flow.training.trainer INFO    Epoch   9: train loss -1.66239 (mse:  0.001, nll: -1.662)\n",
      "22:05 manifold_flow.training.trainer INFO               val. loss  -1.64942 (mse:  0.001, nll: -1.649)\n",
      "22:05 manifold_flow.training.trainer DEBUG   Training epoch 10 / 10\n",
      "22:05 manifold_flow.training.trainer DEBUG     Learning rate: [9.549150281252633e-05]\n",
      "22:09 manifold_flow.training.trainer INFO    Epoch  10: train loss -1.66548 (mse:  0.001, nll: -1.665)\n",
      "22:09 manifold_flow.training.trainer INFO               val. loss  -1.65127 (mse:  0.001, nll: -1.651)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:09 manifold_flow.training.trainer INFO    Early stopping did not improve performance\n",
      "22:09 manifold_flow.training.trainer DEBUG   Training finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-1.01889587, -1.27705722, -1.43039809, -1.52634964, -1.58648968,\n",
       "        -1.62288278, -1.64413167, -1.65604351, -1.66239445, -1.66548191]),\n",
       " array([-1.1595998 , -1.35305155, -1.4729071 , -1.54816154, -1.59409639,\n",
       "        -1.6213636 , -1.63674485, -1.6451611 , -1.64942423, -1.65127181]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_transform = vector_transforms.create_transform(\n",
    "    2, 3,\n",
    "    linear_transform_type=\"permutation\",\n",
    "    base_transform_type=\"affine-coupling\",\n",
    "    context_features=None,\n",
    "    hidden_features=20,\n",
    "    num_transform_blocks=1,\n",
    "    resnet_transform=False,\n",
    ")\n",
    "inner_transform=transforms.ConditionalAffineScalarTransform(features=1)\n",
    "\n",
    "mf = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    inner_transform=inner_transform,\n",
    "    outer_transform=outer_transform\n",
    ")\n",
    "\n",
    "trainer = training.trainer.ManifoldFlowTrainer(mf)\n",
    "trainer.train(\n",
    "    train_dataset,\n",
    "    [training.losses.mse],\n",
    "    loss_weights=[100.],\n",
    "    epochs=epochs // 2,\n",
    "    forward_kwargs={\"mode\":\"projection\"}\n",
    ")\n",
    "trainer.train(\n",
    "    train_dataset,\n",
    "    [training.losses.mse, training.losses.nll],\n",
    "    loss_weights=[0., 1.],\n",
    "    epochs=epochs // 2,\n",
    "    parameters=mf.inner_transform.parameters(),\n",
    "    forward_kwargs={\"mode\":\"mf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22:09 manifold_flow.transforms.proje DEBUG   Set up projection from vector with dimension 2 to vector with dimension 1\n",
      "22:09 manifold_flow.flows.base       DEBUG   Created standard flow with 2.0 M parameters (2.0 M trainable) with an estimated size of 7.9 <B\n",
      "22:09 manifold_flow.training.trainer INFO    Training on CPU with single precision\n",
      "22:09 manifold_flow.training.trainer DEBUG   Initialising training data\n",
      "22:09 manifold_flow.training.trainer DEBUG   Setting up optimizer\n",
      "22:09 manifold_flow.training.trainer DEBUG   Setting up LR scheduler\n",
      "22:09 manifold_flow.training.trainer DEBUG   Using early stopping with infinite patience\n",
      "22:09 manifold_flow.training.trainer DEBUG   Will print training progress every 1 epochs\n",
      "22:09 manifold_flow.training.trainer DEBUG   Beginning main training loop\n",
      "22:09 manifold_flow.training.trainer DEBUG   Training epoch 1 / 20\n",
      "22:09 manifold_flow.training.trainer DEBUG     Learning rate: [0.001]\n",
      "22:10 manifold_flow.training.trainer INFO    Epoch   1: train loss 12713.18611 (nll: 12713.186)\n",
      "22:10 manifold_flow.training.trainer INFO               val. loss  1715.42933 (nll: 1715.429)\n",
      "22:10 manifold_flow.training.trainer DEBUG   Training epoch 2 / 20\n",
      "22:10 manifold_flow.training.trainer DEBUG     Learning rate: [0.001]\n",
      "22:11 manifold_flow.training.trainer INFO    Epoch   2: train loss 482.44447 (nll: 482.444)\n",
      "22:11 manifold_flow.training.trainer INFO               val. loss  320.38133 (nll: 320.381)\n",
      "22:11 manifold_flow.training.trainer DEBUG   Training epoch 3 / 20\n",
      "22:11 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009938441702975688]\n",
      "22:12 manifold_flow.training.trainer INFO    Epoch   3: train loss 275.80822 (nll: 275.808)\n",
      "22:12 manifold_flow.training.trainer INFO               val. loss  15.29392 (nll: 15.294)\n",
      "22:12 manifold_flow.training.trainer DEBUG   Training epoch 4 / 20\n",
      "22:12 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009755282581475768]\n",
      "22:13 manifold_flow.training.trainer INFO    Epoch   4: train loss 31.81459 (nll: 31.815)\n",
      "22:13 manifold_flow.training.trainer INFO               val. loss  18.78179 (nll: 18.782)\n",
      "22:13 manifold_flow.training.trainer DEBUG   Training epoch 5 / 20\n",
      "22:13 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009455032620941839]\n",
      "22:14 manifold_flow.training.trainer INFO    Epoch   5: train loss 25.03069 (nll: 25.031)\n",
      "22:14 manifold_flow.training.trainer INFO               val. loss  32.81990 (nll: 32.820)\n",
      "22:14 manifold_flow.training.trainer DEBUG   Training epoch 6 / 20\n",
      "22:14 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009045084971874737]\n",
      "22:15 manifold_flow.training.trainer INFO    Epoch   6: train loss 22.85505 (nll: 22.855)\n",
      "22:15 manifold_flow.training.trainer INFO               val. loss   7.88320 (nll:  7.883)\n",
      "22:15 manifold_flow.training.trainer DEBUG   Training epoch 7 / 20\n",
      "22:15 manifold_flow.training.trainer DEBUG     Learning rate: [0.0008535533905932737]\n",
      "22:17 manifold_flow.training.trainer INFO    Epoch   7: train loss 19.41279 (nll: 19.413)\n",
      "22:17 manifold_flow.training.trainer INFO               val. loss  17.47900 (nll: 17.479)\n",
      "22:17 manifold_flow.training.trainer DEBUG   Training epoch 8 / 20\n",
      "22:17 manifold_flow.training.trainer DEBUG     Learning rate: [0.0007938926261462367]\n",
      "22:18 manifold_flow.training.trainer INFO    Epoch   8: train loss 15.89848 (nll: 15.898)\n",
      "22:18 manifold_flow.training.trainer INFO               val. loss  24.28073 (nll: 24.281)\n",
      "22:18 manifold_flow.training.trainer DEBUG   Training epoch 9 / 20\n",
      "22:18 manifold_flow.training.trainer DEBUG     Learning rate: [0.0007269952498697733]\n",
      "22:19 manifold_flow.training.trainer INFO    Epoch   9: train loss 13.66299 (nll: 13.663)\n",
      "22:19 manifold_flow.training.trainer INFO               val. loss  16.39103 (nll: 16.391)\n",
      "22:19 manifold_flow.training.trainer DEBUG   Training epoch 10 / 20\n",
      "22:19 manifold_flow.training.trainer DEBUG     Learning rate: [0.0006545084971874737]\n",
      "22:20 manifold_flow.training.trainer INFO    Epoch  10: train loss 10.58294 (nll: 10.583)\n",
      "22:20 manifold_flow.training.trainer INFO               val. loss   8.68398 (nll:  8.684)\n",
      "22:20 manifold_flow.training.trainer DEBUG   Training epoch 11 / 20\n",
      "22:20 manifold_flow.training.trainer DEBUG     Learning rate: [0.0005782172325201155]\n",
      "22:21 manifold_flow.training.trainer INFO    Epoch  11: train loss  8.20907 (nll:  8.209)\n",
      "22:21 manifold_flow.training.trainer INFO               val. loss  12.01897 (nll: 12.019)\n",
      "22:21 manifold_flow.training.trainer DEBUG   Training epoch 12 / 20\n",
      "22:21 manifold_flow.training.trainer DEBUG     Learning rate: [0.0005]\n",
      "22:22 manifold_flow.training.trainer INFO    Epoch  12: train loss  6.06801 (nll:  6.068)\n",
      "22:22 manifold_flow.training.trainer INFO               val. loss   1.54411 (nll:  1.544)\n",
      "22:22 manifold_flow.training.trainer DEBUG   Training epoch 13 / 20\n",
      "22:22 manifold_flow.training.trainer DEBUG     Learning rate: [0.0004217827674798847]\n",
      "22:24 manifold_flow.training.trainer INFO    Epoch  13: train loss  4.54541 (nll:  4.545)\n",
      "22:24 manifold_flow.training.trainer INFO               val. loss   7.37956 (nll:  7.380)\n",
      "22:24 manifold_flow.training.trainer DEBUG   Training epoch 14 / 20\n",
      "22:24 manifold_flow.training.trainer DEBUG     Learning rate: [0.00034549150281252633]\n",
      "22:25 manifold_flow.training.trainer INFO    Epoch  14: train loss  3.28558 (nll:  3.286)\n",
      "22:25 manifold_flow.training.trainer INFO               val. loss   1.35170 (nll:  1.352)\n",
      "22:25 manifold_flow.training.trainer DEBUG   Training epoch 15 / 20\n",
      "22:25 manifold_flow.training.trainer DEBUG     Learning rate: [0.00027300475013022663]\n",
      "22:26 manifold_flow.training.trainer INFO    Epoch  15: train loss  2.14466 (nll:  2.145)\n",
      "22:26 manifold_flow.training.trainer INFO               val. loss   2.67388 (nll:  2.674)\n",
      "22:26 manifold_flow.training.trainer DEBUG   Training epoch 16 / 20\n",
      "22:26 manifold_flow.training.trainer DEBUG     Learning rate: [0.00020610737385376348]\n",
      "22:27 manifold_flow.training.trainer INFO    Epoch  16: train loss  1.42414 (nll:  1.424)\n",
      "22:27 manifold_flow.training.trainer INFO               val. loss   1.25002 (nll:  1.250)\n",
      "22:27 manifold_flow.training.trainer DEBUG   Training epoch 17 / 20\n",
      "22:27 manifold_flow.training.trainer DEBUG     Learning rate: [0.00014644660940672628]\n",
      "22:28 manifold_flow.training.trainer INFO    Epoch  17: train loss  0.91757 (nll:  0.918)\n",
      "22:28 manifold_flow.training.trainer INFO               val. loss   0.89207 (nll:  0.892)\n",
      "22:28 manifold_flow.training.trainer DEBUG   Training epoch 18 / 20\n",
      "22:28 manifold_flow.training.trainer DEBUG     Learning rate: [9.549150281252633e-05]\n",
      "22:29 manifold_flow.training.trainer INFO    Epoch  18: train loss  0.87453 (nll:  0.875)\n",
      "22:29 manifold_flow.training.trainer INFO               val. loss   0.99597 (nll:  0.996)\n",
      "22:29 manifold_flow.training.trainer DEBUG   Training epoch 19 / 20\n",
      "22:29 manifold_flow.training.trainer DEBUG     Learning rate: [5.449673790581611e-05]\n",
      "08:05 manifold_flow.training.trainer INFO    Epoch  19: train loss  0.95453 (nll:  0.955)\n",
      "08:05 manifold_flow.training.trainer INFO               val. loss   0.79629 (nll:  0.796)\n",
      "08:05 manifold_flow.training.trainer DEBUG   Training epoch 20 / 20\n",
      "08:05 manifold_flow.training.trainer DEBUG     Learning rate: [2.4471741852423235e-05]\n",
      "08:07 manifold_flow.training.trainer INFO    Epoch  20: train loss  0.45752 (nll:  0.458)\n",
      "08:07 manifold_flow.training.trainer INFO               val. loss   0.51329 (nll:  0.513)\n",
      "08:07 manifold_flow.training.trainer INFO    Early stopping did not improve performance\n",
      "08:07 manifold_flow.training.trainer DEBUG   Training finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1.27131861e+04, 4.82444472e+02, 2.75808219e+02, 3.18145906e+01,\n",
       "        2.50306850e+01, 2.28550479e+01, 1.94127929e+01, 1.58984839e+01,\n",
       "        1.36629876e+01, 1.05829446e+01, 8.20907074e+00, 6.06801492e+00,\n",
       "        4.54540686e+00, 3.28558373e+00, 2.14466435e+00, 1.42413969e+00,\n",
       "        9.17568075e-01, 8.74533385e-01, 9.54526337e-01, 4.57515240e-01]),\n",
       " array([1.71542933e+03, 3.20381331e+02, 1.52939219e+01, 1.87817877e+01,\n",
       "        3.28198969e+01, 7.88320492e+00, 1.74790016e+01, 2.42807298e+01,\n",
       "        1.63910255e+01, 8.68397510e+00, 1.20189663e+01, 1.54411390e+00,\n",
       "        7.37955642e+00, 1.35169972e+00, 2.67387519e+00, 1.25002303e+00,\n",
       "        8.92068111e-01, 9.95971039e-01, 7.96293428e-01, 5.13291512e-01]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_transform = vector_transforms.create_transform(\n",
    "    2, 5,\n",
    "    linear_transform_type=\"permutation\",\n",
    "    base_transform_type=\"affine-coupling\",\n",
    "    context_features=None\n",
    ")\n",
    "inner_transform=transforms.ConditionalAffineScalarTransform(features=1)\n",
    "\n",
    "pie = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    outer_transform=outer_transform,\n",
    "    inner_transform=inner_transform,\n",
    ")\n",
    "\n",
    "trainer = training.trainer.ManifoldFlowTrainer(pie)\n",
    "trainer.train(\n",
    "    train_dataset,\n",
    "    [training.losses.nll],\n",
    "    loss_weights=[1.],\n",
    "    epochs=epochs,\n",
    "    forward_kwargs={\"mode\":\"pie\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice of PIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:07 manifold_flow.transforms.proje DEBUG   Set up projection from vector with dimension 2 to vector with dimension 1\n",
      "08:07 manifold_flow.flows.base       DEBUG   Created standard flow with 2.0 M parameters (2.0 M trainable) with an estimated size of 7.9 <B\n",
      "08:07 manifold_flow.training.trainer INFO    Training on CPU with single precision\n",
      "08:07 manifold_flow.training.trainer DEBUG   Initialising training data\n",
      "08:07 manifold_flow.training.trainer DEBUG   Setting up optimizer\n",
      "08:07 manifold_flow.training.trainer DEBUG   Setting up LR scheduler\n",
      "08:07 manifold_flow.training.trainer DEBUG   Using early stopping with infinite patience\n",
      "08:07 manifold_flow.training.trainer DEBUG   Will print training progress every 1 epochs\n",
      "08:07 manifold_flow.training.trainer DEBUG   Beginning main training loop\n",
      "08:07 manifold_flow.training.trainer DEBUG   Training epoch 1 / 10\n",
      "08:07 manifold_flow.training.trainer DEBUG     Learning rate: [0.001]\n",
      "08:08 manifold_flow.training.trainer INFO    Epoch   1: train loss  0.99553 (mse:  0.010)\n",
      "08:08 manifold_flow.training.trainer INFO               val. loss   0.49383 (mse:  0.005)\n",
      "08:08 manifold_flow.training.trainer DEBUG   Training epoch 2 / 10\n",
      "08:08 manifold_flow.training.trainer DEBUG     Learning rate: [0.001]\n",
      "08:09 manifold_flow.training.trainer INFO    Epoch   2: train loss  0.41591 (mse:  0.004)\n",
      "08:09 manifold_flow.training.trainer INFO               val. loss   0.12525 (mse:  0.001)\n",
      "08:09 manifold_flow.training.trainer DEBUG   Training epoch 3 / 10\n",
      "08:09 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009755282581475768]\n",
      "08:11 manifold_flow.training.trainer INFO    Epoch   3: train loss  0.37946 (mse:  0.004)\n",
      "08:11 manifold_flow.training.trainer INFO               val. loss   0.16160 (mse:  0.002)\n",
      "08:11 manifold_flow.training.trainer DEBUG   Training epoch 4 / 10\n",
      "08:11 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009045084971874737]\n",
      "08:12 manifold_flow.training.trainer INFO    Epoch   4: train loss  0.29389 (mse:  0.003)\n",
      "08:12 manifold_flow.training.trainer INFO               val. loss   0.21401 (mse:  0.002)\n",
      "08:12 manifold_flow.training.trainer DEBUG   Training epoch 5 / 10\n",
      "08:12 manifold_flow.training.trainer DEBUG     Learning rate: [0.0007938926261462367]\n",
      "08:13 manifold_flow.training.trainer INFO    Epoch   5: train loss  0.26811 (mse:  0.003)\n",
      "08:13 manifold_flow.training.trainer INFO               val. loss   0.13579 (mse:  0.001)\n",
      "08:13 manifold_flow.training.trainer DEBUG   Training epoch 6 / 10\n",
      "08:13 manifold_flow.training.trainer DEBUG     Learning rate: [0.0006545084971874737]\n",
      "08:15 manifold_flow.training.trainer INFO    Epoch   6: train loss  0.17890 (mse:  0.002)\n",
      "08:15 manifold_flow.training.trainer INFO               val. loss   0.06813 (mse:  0.001)\n",
      "08:15 manifold_flow.training.trainer DEBUG   Training epoch 7 / 10\n",
      "08:15 manifold_flow.training.trainer DEBUG     Learning rate: [0.0005]\n",
      "08:16 manifold_flow.training.trainer INFO    Epoch   7: train loss  0.18378 (mse:  0.002)\n",
      "08:16 manifold_flow.training.trainer INFO               val. loss   0.21732 (mse:  0.002)\n",
      "08:16 manifold_flow.training.trainer DEBUG   Training epoch 8 / 10\n",
      "08:16 manifold_flow.training.trainer DEBUG     Learning rate: [0.00034549150281252633]\n",
      "08:17 manifold_flow.training.trainer INFO    Epoch   8: train loss  0.10885 (mse:  0.001)\n",
      "08:17 manifold_flow.training.trainer INFO               val. loss   0.03625 (mse:  0.000)\n",
      "08:17 manifold_flow.training.trainer DEBUG   Training epoch 9 / 10\n",
      "08:17 manifold_flow.training.trainer DEBUG     Learning rate: [0.00020610737385376348]\n",
      "08:18 manifold_flow.training.trainer INFO    Epoch   9: train loss  0.07700 (mse:  0.001)\n",
      "08:18 manifold_flow.training.trainer INFO               val. loss   0.18805 (mse:  0.002)\n",
      "08:18 manifold_flow.training.trainer DEBUG   Training epoch 10 / 10\n",
      "08:18 manifold_flow.training.trainer DEBUG     Learning rate: [9.549150281252633e-05]\n",
      "08:20 manifold_flow.training.trainer INFO    Epoch  10: train loss  0.06402 (mse:  0.001)\n",
      "08:20 manifold_flow.training.trainer INFO               val. loss   0.02969 (mse:  0.000)\n",
      "08:20 manifold_flow.training.trainer INFO    Early stopping did not improve performance\n",
      "08:20 manifold_flow.training.trainer DEBUG   Training finished\n",
      "08:20 manifold_flow.training.trainer DEBUG   Initialising training data\n",
      "08:20 manifold_flow.training.trainer DEBUG   Setting up optimizer\n",
      "08:20 manifold_flow.training.trainer DEBUG   Setting up LR scheduler\n",
      "08:20 manifold_flow.training.trainer DEBUG   Using early stopping with infinite patience\n",
      "08:20 manifold_flow.training.trainer DEBUG   Will print training progress every 1 epochs\n",
      "08:20 manifold_flow.training.trainer DEBUG   Beginning main training loop\n",
      "08:20 manifold_flow.training.trainer DEBUG   Training epoch 1 / 10\n",
      "08:20 manifold_flow.training.trainer DEBUG     Learning rate: [0.001]\n",
      "08:21 manifold_flow.training.trainer INFO    Epoch   1: train loss 21.77820 (mse:  0.000, nll: 21.778)\n",
      "08:21 manifold_flow.training.trainer INFO               val. loss  -2.16034 (mse:  0.000, nll: -2.160)\n",
      "08:21 manifold_flow.training.trainer DEBUG   Training epoch 2 / 10\n",
      "08:21 manifold_flow.training.trainer DEBUG     Learning rate: [0.001]\n",
      "08:22 manifold_flow.training.trainer INFO    Epoch   2: train loss 24.37821 (mse:  0.000, nll: 24.378)\n",
      "08:22 manifold_flow.training.trainer INFO               val. loss  -2.16034 (mse:  0.000, nll: -2.160)\n",
      "08:22 manifold_flow.training.trainer DEBUG   Training epoch 3 / 10\n",
      "08:22 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009755282581475768]\n",
      "08:23 manifold_flow.training.trainer INFO    Epoch   3: train loss 24.53435 (mse:  0.000, nll: 24.534)\n",
      "08:23 manifold_flow.training.trainer INFO               val. loss  -2.16034 (mse:  0.000, nll: -2.160)\n",
      "08:23 manifold_flow.training.trainer DEBUG   Training epoch 4 / 10\n",
      "08:23 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009045084971874737]\n",
      "08:25 manifold_flow.training.trainer INFO    Epoch   4: train loss 22.75941 (mse:  0.000, nll: 22.759)\n",
      "08:25 manifold_flow.training.trainer INFO               val. loss  -2.16034 (mse:  0.000, nll: -2.160)\n",
      "08:25 manifold_flow.training.trainer DEBUG   Training epoch 5 / 10\n",
      "08:25 manifold_flow.training.trainer DEBUG     Learning rate: [0.0007938926261462367]\n",
      "08:26 manifold_flow.training.trainer INFO    Epoch   5: train loss 24.39792 (mse:  0.000, nll: 24.398)\n",
      "08:26 manifold_flow.training.trainer INFO               val. loss  -2.16034 (mse:  0.000, nll: -2.160)\n",
      "08:26 manifold_flow.training.trainer DEBUG   Training epoch 6 / 10\n",
      "08:26 manifold_flow.training.trainer DEBUG     Learning rate: [0.0006545084971874737]\n",
      "08:28 manifold_flow.training.trainer INFO    Epoch   6: train loss 21.69103 (mse:  0.000, nll: 21.691)\n",
      "08:28 manifold_flow.training.trainer INFO               val. loss  -2.16034 (mse:  0.000, nll: -2.160)\n",
      "08:28 manifold_flow.training.trainer DEBUG   Training epoch 7 / 10\n",
      "08:28 manifold_flow.training.trainer DEBUG     Learning rate: [0.0005]\n",
      "08:29 manifold_flow.training.trainer INFO    Epoch   7: train loss 22.63266 (mse:  0.000, nll: 22.633)\n",
      "08:29 manifold_flow.training.trainer INFO               val. loss  -2.16034 (mse:  0.000, nll: -2.160)\n",
      "08:29 manifold_flow.training.trainer DEBUG   Training epoch 8 / 10\n",
      "08:29 manifold_flow.training.trainer DEBUG     Learning rate: [0.00034549150281252633]\n",
      "08:31 manifold_flow.training.trainer INFO    Epoch   8: train loss 23.44535 (mse:  0.000, nll: 23.445)\n",
      "08:31 manifold_flow.training.trainer INFO               val. loss  -2.16034 (mse:  0.000, nll: -2.160)\n",
      "08:31 manifold_flow.training.trainer DEBUG   Training epoch 9 / 10\n",
      "08:31 manifold_flow.training.trainer DEBUG     Learning rate: [0.00020610737385376348]\n",
      "08:33 manifold_flow.training.trainer INFO    Epoch   9: train loss 22.97777 (mse:  0.000, nll: 22.978)\n",
      "08:33 manifold_flow.training.trainer INFO               val. loss  -2.16034 (mse:  0.000, nll: -2.160)\n",
      "08:33 manifold_flow.training.trainer DEBUG   Training epoch 10 / 10\n",
      "08:33 manifold_flow.training.trainer DEBUG     Learning rate: [9.549150281252633e-05]\n",
      "08:34 manifold_flow.training.trainer INFO    Epoch  10: train loss 24.11370 (mse:  0.000, nll: 24.114)\n",
      "08:34 manifold_flow.training.trainer INFO               val. loss  -2.16034 (mse:  0.000, nll: -2.160)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:34 manifold_flow.training.trainer INFO    Early stopping after epoch 2, with loss -2.16034 compared to final loss -2.16034\n",
      "08:34 manifold_flow.training.trainer DEBUG   Training finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([21.77820404, 24.37821187, 24.53435369, 22.75941278, 24.39792132,\n",
       "        21.6910315 , 22.63265838, 23.44534783, 22.97776724, 24.11370334]),\n",
       " array([-2.1603359 , -2.16033592, -2.16033589, -2.16033591, -2.16033589,\n",
       "        -2.16033591, -2.1603359 , -2.1603359 , -2.1603359 , -2.16033589]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_transform = vector_transforms.create_transform(\n",
    "    2, 5,\n",
    "    linear_transform_type=\"permutation\",\n",
    "    base_transform_type=\"affine-coupling\",\n",
    "    context_features=None\n",
    ")\n",
    "inner_transform=transforms.ConditionalAffineScalarTransform(features=1)\n",
    "\n",
    "slice_of_pie = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    outer_transform=outer_transform,\n",
    "    inner_transform=inner_transform,\n",
    ")\n",
    "\n",
    "trainer = training.trainer.ManifoldFlowTrainer(slice_of_pie)\n",
    "trainer.train(\n",
    "    train_dataset,\n",
    "    [training.losses.mse],\n",
    "    loss_weights=[100.],\n",
    "    epochs=epochs // 2,\n",
    "    forward_kwargs={\"mode\": \"projection\"}\n",
    ")\n",
    "trainer.train(\n",
    "    train_dataset,\n",
    "    [training.losses.mse, training.losses.nll],\n",
    "    loss_weights=[0., 1.],\n",
    "    epochs=epochs // 2,\n",
    "    parameters=mf.inner_transform.parameters(),\n",
    "    forward_kwargs={\"mode\": \"slice\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08:34 manifold_flow.flows.base       DEBUG   Created standard flow with 2.0 M parameters (2.0 M trainable) with an estimated size of 7.9 <B\n",
      "08:34 manifold_flow.training.trainer INFO    Training on CPU with single precision\n",
      "08:34 manifold_flow.training.trainer DEBUG   Initialising training data\n",
      "08:34 manifold_flow.training.trainer DEBUG   Setting up optimizer\n",
      "08:34 manifold_flow.training.trainer DEBUG   Setting up LR scheduler\n",
      "08:34 manifold_flow.training.trainer DEBUG   Using early stopping with infinite patience\n",
      "08:34 manifold_flow.training.trainer DEBUG   Will print training progress every 1 epochs\n",
      "08:34 manifold_flow.training.trainer DEBUG   Beginning main training loop\n",
      "08:34 manifold_flow.training.trainer DEBUG   Training epoch 1 / 20\n",
      "08:34 manifold_flow.training.trainer DEBUG     Learning rate: [0.001]\n",
      "08:35 manifold_flow.training.trainer INFO    Epoch   1: train loss  1.88893 (nll:  1.889)\n",
      "08:35 manifold_flow.training.trainer INFO               val. loss   1.85694 (nll:  1.857)\n",
      "08:35 manifold_flow.training.trainer DEBUG   Training epoch 2 / 20\n",
      "08:35 manifold_flow.training.trainer DEBUG     Learning rate: [0.001]\n",
      "08:36 manifold_flow.training.trainer INFO    Epoch   2: train loss  1.86154 (nll:  1.862)\n",
      "08:36 manifold_flow.training.trainer INFO               val. loss   1.85333 (nll:  1.853)\n",
      "08:36 manifold_flow.training.trainer DEBUG   Training epoch 3 / 20\n",
      "08:36 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009938441702975688]\n",
      "08:38 manifold_flow.training.trainer INFO    Epoch   3: train loss  1.85870 (nll:  1.859)\n",
      "08:38 manifold_flow.training.trainer INFO               val. loss   1.85659 (nll:  1.857)\n",
      "08:38 manifold_flow.training.trainer DEBUG   Training epoch 4 / 20\n",
      "08:38 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009755282581475768]\n",
      "08:39 manifold_flow.training.trainer INFO    Epoch   4: train loss  1.85620 (nll:  1.856)\n",
      "08:39 manifold_flow.training.trainer INFO               val. loss   1.85592 (nll:  1.856)\n",
      "08:39 manifold_flow.training.trainer DEBUG   Training epoch 5 / 20\n",
      "08:39 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009455032620941839]\n",
      "08:40 manifold_flow.training.trainer INFO    Epoch   5: train loss  1.85590 (nll:  1.856)\n",
      "08:40 manifold_flow.training.trainer INFO               val. loss   1.85251 (nll:  1.853)\n",
      "08:40 manifold_flow.training.trainer DEBUG   Training epoch 6 / 20\n",
      "08:40 manifold_flow.training.trainer DEBUG     Learning rate: [0.0009045084971874737]\n",
      "08:41 manifold_flow.training.trainer INFO    Epoch   6: train loss  1.85549 (nll:  1.855)\n",
      "08:41 manifold_flow.training.trainer INFO               val. loss   1.84957 (nll:  1.850)\n",
      "08:41 manifold_flow.training.trainer DEBUG   Training epoch 7 / 20\n",
      "08:41 manifold_flow.training.trainer DEBUG     Learning rate: [0.0008535533905932737]\n",
      "08:42 manifold_flow.training.trainer INFO    Epoch   7: train loss  1.85455 (nll:  1.855)\n",
      "08:42 manifold_flow.training.trainer INFO               val. loss   1.84992 (nll:  1.850)\n",
      "08:42 manifold_flow.training.trainer DEBUG   Training epoch 8 / 20\n",
      "08:42 manifold_flow.training.trainer DEBUG     Learning rate: [0.0007938926261462367]\n",
      "08:44 manifold_flow.training.trainer INFO    Epoch   8: train loss  1.85364 (nll:  1.854)\n",
      "08:44 manifold_flow.training.trainer INFO               val. loss   1.86203 (nll:  1.862)\n",
      "08:44 manifold_flow.training.trainer DEBUG   Training epoch 9 / 20\n",
      "08:44 manifold_flow.training.trainer DEBUG     Learning rate: [0.0007269952498697733]\n"
     ]
    }
   ],
   "source": [
    "transform = vector_transforms.create_transform(\n",
    "    2, 5,\n",
    "    linear_transform_type=\"permutation\",\n",
    "    base_transform_type=\"affine-coupling\",\n",
    "    context_features=None\n",
    ")\n",
    "sf = Flow(\n",
    "    data_dim=2,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "trainer = training.trainer.ManifoldFlowTrainer(sf)\n",
    "trainer.train(\n",
    "    train_dataset,\n",
    "    [training.losses.nll],\n",
    "    loss_weights=[1.],\n",
    "    epochs=epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the generative performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen_sf = sf.sample(n=1000).detach().numpy()\n",
    "x_gen_mf = mf.sample(n=1000).detach().numpy()\n",
    "x_gen_pie = pie.sample(n=1000).detach().numpy()\n",
    "x_gen_pie_full = pie.sample(n=1000, sample_orthogonal=True).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance from manifold, true likelihood of generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logp_min = -1000\n",
    "\n",
    "logp_gen_sf = simulator.log_density(x_gen_sf)\n",
    "logp_gen_mf = simulator.log_density(x_gen_mf)\n",
    "logp_gen_pie = simulator.log_density(x_gen_pie)\n",
    "logp_gen_pie_full = simulator.log_density(x_gen_pie_full)\n",
    "\n",
    "logp_gen_sf[(~np.isfinite(logp_gen_sf)) + (logp_gen_sf<logp_min)] = logp_min\n",
    "logp_gen_mf[(~np.isfinite(logp_gen_mf)) + (logp_gen_mf<logp_min)] = logp_min\n",
    "logp_gen_pie[(~np.isfinite(logp_gen_pie)) + (logp_gen_pie<logp_min)] = logp_min\n",
    "logp_gen_pie_full[(~np.isfinite(logp_gen_pie_full)) + (logp_gen_pie_full<logp_min)] = logp_min\n",
    "\n",
    "mean_logp_gen_sf = np.mean(logp_gen_sf)\n",
    "mean_logp_gen_mf = np.mean(logp_gen_mf)\n",
    "mean_logp_gen_pie = np.mean(logp_gen_pie)\n",
    "mean_logp_gen_pie_full = np.mean(logp_gen_pie_full)\n",
    "\n",
    "distance_from_manifold_gen_sf = np.mean(np.abs(np.sum(x_gen_sf**2, axis=1)**0.5 - 1))\n",
    "distance_from_manifold_gen_mf = np.mean(np.abs(np.sum(x_gen_mf**2, axis=1)**0.5 - 1))\n",
    "distance_from_manifold_gen_pie = np.mean(np.abs(np.sum(x_gen_pie**2, axis=1)**0.5 - 1))\n",
    "distance_from_manifold_gen_pie_full = np.mean(np.abs(np.sum(x_gen_pie_full**2, axis=1)**0.5 - 1))\n",
    "\n",
    "print(\"Mean true log likelihood of samples generated from flows (higher is better):\")\n",
    "print(\"  Standard flow:      {:>6.1f}\".format(mean_logp_gen_sf))\n",
    "print(\"  PIE:                {:>6.1f}\".format(mean_logp_gen_pie))\n",
    "print(\"  PIE (sampling all): {:>6.1f}\".format(mean_logp_gen_pie_full))\n",
    "print(\"  Manifold flow:      {:>6.1f}\".format(mean_logp_gen_mf))\n",
    "\n",
    "print(\"Mean Euclidean distance between samples generated from flows and true manifold (lower is better):\")\n",
    "print(\"  Standard flow:      {:>6.2f}\".format(distance_from_manifold_gen_sf))\n",
    "print(\"  PIE:                {:>6.2f}\".format(distance_from_manifold_gen_pie))\n",
    "print(\"  PIE (sampling all): {:>6.2f}\".format(distance_from_manifold_gen_pie_full))\n",
    "print(\"  Manifold flow:      {:>6.2f}\".format(distance_from_manifold_gen_mf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 10\n",
    "res = 250\n",
    "x_range = np.linspace(-1.5,1.5,res)\n",
    "y_range = np.linspace(-1.5,1.5,res)\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "x_grid = np.concatenate((xx.reshape((-1,1)), yy.reshape((-1,1))), axis=1)\n",
    "logp_grid = simulator.log_density(x_grid).reshape((res, res))\n",
    "logp_grid[~np.isfinite(logp_grid)] = -1000000.\n",
    "zmin, zmax = np.max(logp_grid) - 10., np.max(logp_grid)\n",
    "\n",
    "fig = plt.figure(figsize=(6,5))\n",
    "ax = plt.gca()\n",
    "\n",
    "pcm = plt.imshow(\n",
    "    np.clip(logp_grid, zmin, zmax),\n",
    "    extent=(-1.5,1.5,-1.5,1.5),\n",
    "    origin=\"lower\",\n",
    "    cmap=\"Greys\",\n",
    "    norm=matplotlib.colors.Normalize(zmin, zmax),\n",
    "    interpolation='nearest'\n",
    ")\n",
    "cb = plt.colorbar(pcm, extend=\"both\")\n",
    "\n",
    "plt.scatter(x_gen_sf[::skip,0], x_gen_sf[::skip,1], s=10., c=\"C0\", label=\"Standard flow\")\n",
    "plt.scatter(x_gen_pie[::skip,0], x_gen_pie[::skip,1], s=10., c=\"C1\", label=\"PIE\")\n",
    "plt.scatter(x_gen_pie_full[::skip,0], x_gen_pie_full[::skip,1], s=10., c=\"C2\", label=\"PIE (sampling all)\")\n",
    "plt.scatter(x_gen_mf[::skip,0], x_gen_mf[::skip,1], s=10., c=\"C3\", label=\"Manifold flow\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "cb.set_label(\"True log density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"spherical_gaussian_2d_generation.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize learned likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 100\n",
    "x_range = np.linspace(-1.5,1.5,res)\n",
    "y_range = np.linspace(-1.5,1.5,res)\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "x_grid = np.concatenate((xx.reshape((-1,1)), yy.reshape((-1,1))), axis=1)\n",
    "x_grid_tensor = torch.FloatTensor(x_grid)\n",
    "\n",
    "learned_logp_grid_mf = mf.log_prob(x_grid_tensor, mode=\"mf\").detach().numpy().reshape((res, res))\n",
    "learned_logp_grid_sf = sf.log_prob(x_grid_tensor).detach().numpy().reshape((res, res))\n",
    "learned_logp_grid_pie = pie.log_prob(x_grid_tensor, mode=\"pie\").detach().numpy().reshape((res, res))\n",
    "learned_logp_grid_slice_of_pie = slice_of_pie.log_prob(x_grid_tensor, mode=\"slice\").detach().numpy().reshape((res, res))\n",
    "\n",
    "logp_grid_truth = simulator.log_density(x_grid).reshape((res, res))\n",
    "logp_grid_truth[~np.isfinite(logp_grid_truth)] = -1000000.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 500\n",
    "\n",
    "fig = plt.figure(figsize=(12,10))\n",
    "\n",
    "for i, (label, logp) in enumerate(zip(\n",
    "    [\"True log density\", \"Standard flow log density\", \"PIE log density\", \"Manifold flow log density\"],\n",
    "    [logp_grid_truth, learned_logp_grid_sf, learned_logp_grid_pie, learned_logp_grid_mf]\n",
    "     )):\n",
    "    ax = plt.subplot(2,2,i+1)\n",
    "\n",
    "    zmin, zmax = np.max(logp_grid_truth) - 7., np.max(logp_grid_truth) + 3.\n",
    "\n",
    "    pcm = plt.imshow(\n",
    "        np.clip(logp, zmin, zmax),\n",
    "        extent=(-1.5, 1.5, -1.5, 1.5),\n",
    "        origin=\"lower\",\n",
    "        cmap=\"viridis\",\n",
    "        norm=matplotlib.colors.Normalize(zmin, zmax),\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "    cb = plt.colorbar(pcm, extend=\"both\")\n",
    "    plt.scatter(x[::skip,0], x[::skip,1], s=5., c=\"black\")\n",
    "\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlabel(\"$x_1$\")\n",
    "    plt.ylabel(\"$x_2$\")\n",
    "    cb.set_label(label)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"spherical_gaussian_2d_log_prob.pdf\", dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = SphericalGaussianSimulator(1,2,epsilon=epsilon).sample(100)\n",
    "x_in = torch.FloatTensor(x_in)\n",
    "x_out = mf(x_in)[0]\n",
    "x_in, x_out = x_in.detach().numpy(), x_out.detach().numpy()\n",
    "dx = x_out - x_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.gca()\n",
    "plt.scatter(x_in[:,0], x_in[:,1], s=15., c=\"C1\")\n",
    "plt.scatter(x_out[:,0], x_out[:,1], s=15., c=\"C0\")\n",
    "plt.quiver(\n",
    "    x_in[:,0], x_in[:,1], dx[:,0], dx[:,1],\n",
    "    angles='xy', scale_units='xy', scale=1., width=2.e-3, alpha=1.\n",
    ")\n",
    "\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"spherical_gaussian_2d_reconstruction.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 51\n",
    "x_range = np.linspace(-1.5,1.5,res)\n",
    "y_range = np.linspace(-1.5,1.5,res)\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "x_grid = np.concatenate((xx.reshape((-1,1)), yy.reshape((-1,1))), axis=1)\n",
    "x_grid_tensor = torch.FloatTensor(x_grid)\n",
    "\n",
    "_, _, u = mf(x_grid_tensor)\n",
    "u = u.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zmin, zmax = np.mean(u) - np.std(u), np.mean(u) + np.std(u)\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "ax = plt.gca()\n",
    "\n",
    "pcm = plt.pcolormesh(\n",
    "    x_range, y_range,\n",
    "    np.clip(np.clip(u, zmin, zmax).reshape(res, res), zmin, zmax),\n",
    "    cmap=\"viridis\", norm=matplotlib.colors.Normalize(zmin, zmax)\n",
    ")\n",
    "cb = plt.colorbar(pcm, extend=\"both\")\n",
    "plt.scatter(x_gen_mf[:,0], x_gen_mf[:,1], s=5., c=\"black\")\n",
    "\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "cb.set_label(\"$\\log \\; \\hat{p}(x)$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"spherical_gaussian_2d_latent.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
