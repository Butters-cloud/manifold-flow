{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spherical Gaussian experiment (2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import logging\n",
    "\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from manifold_flow import transforms, utils, distributions, training\n",
    "from manifold_flow.flows import Flow, ManifoldFlow\n",
    "from manifold_flow import nn as nn_\n",
    "from experiments.simulators.spherical_simulator import SphericalGaussianSimulator\n",
    "from experiments.utils.models import create_vector_transform\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)-5.5s %(name)-30.30s %(levelname)-7.7s %(message)s\",\n",
    "    datefmt=\"%H:%M\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "# Output of all other modules (e.g. matplotlib)\n",
    "for key in logging.Logger.manager.loggerDict:\n",
    "    if \"experiments\" not in key and \"manifold_flow\" not in key:\n",
    "        logging.getLogger(key).setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 12\n",
    "n_train = 100000\n",
    "epsilon = 0.01\n",
    "train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = SphericalGaussianSimulator(latent_dim=1, data_dim=2, epsilon=epsilon)\n",
    "x_sim = simulator.sample(n_train)\n",
    "x_sim_tensor = torch.from_numpy(x_sim)\n",
    "train_dataset = TensorDataset(x_sim_tensor, x_sim_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 200\n",
    "x_range = np.linspace(-1.4,1.4,res)\n",
    "y_range = np.linspace(-1.4,1.4,res)\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "x_grid = np.concatenate((xx.reshape((-1,1)), yy.reshape((-1,1))), axis=1)\n",
    "logp_grid = simulator.log_density(x_grid, precise=True).reshape((res, res))\n",
    "logp_grid[~np.isfinite(logp_grid)] = -1000000.\n",
    "\n",
    "zmin, zmax = np.max(logp_grid) - 10, np.max(logp_grid)\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "ax = plt.gca()\n",
    "\n",
    "pcm = plt.imshow(\n",
    "    np.clip(logp_grid, zmin, zmax),\n",
    "    extent=(-1.4,1.4,-1.4,1.4),\n",
    "    origin=\"lower\",\n",
    "    cmap=\"viridis\", norm=matplotlib.colors.Normalize(zmin, zmax),\n",
    "    interpolation='nearest'\n",
    ")\n",
    "cb = plt.colorbar(pcm, extend=\"both\")\n",
    "plt.scatter(x_sim[::50,0], x_sim[::50,1], s=2., c=\"black\", alpha=1.)\n",
    "\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "cb.set_label(\"$\\log \\; p(x)$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"spherical_gaussian_2d_data.pdf\", dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_size = (x_range[1] - x_range[0]) * (y_range[1] - y_range[0])\n",
    "\n",
    "print(\"Integral over density =\", np.sum(np.exp(logp_grid) * pixel_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifold flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_transform = create_vector_transform(\n",
    "    2, 5,\n",
    "    linear_transform_type=\"permutation\",\n",
    "    base_transform_type=\"affine-coupling\",\n",
    "    context_features=None,\n",
    "    hidden_features=100,\n",
    "    num_transform_blocks=1,\n",
    "    resnet_transform=False,\n",
    ")\n",
    "inner_transform=transforms.ConditionalAffineScalarTransform(features=1)\n",
    "\n",
    "mf = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    inner_transform=inner_transform,\n",
    "    outer_transform=outer_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    trainer = training.trainer.ManifoldFlowTrainer(mf)\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.mse],\n",
    "        loss_weights=[100.],\n",
    "        epochs=epochs // 3,\n",
    "        forward_kwargs={\"mode\":\"projection\"}\n",
    "    )\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.mse, training.losses.nll],\n",
    "        loss_weights=[100., 0.1],\n",
    "        epochs=epochs // 3,\n",
    "        forward_kwargs={\"mode\":\"mf\"}\n",
    "    )\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.mse, training.losses.nll],\n",
    "        loss_weights=[0., 1.],\n",
    "        epochs=epochs // 3,\n",
    "        parameters=mf.inner_transform.parameters(),\n",
    "        forward_kwargs={\"mode\":\"mf\"}\n",
    "    )\n",
    "    torch.save(mf.state_dict(), \"../data/models/mf_1_spherical_gaussian_1_2_0.010.pt\")\n",
    "else:\n",
    "    mf.load_state_dict(torch.load(\"../data/models/mf_1_spherical_gaussian_1_2_0.010.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outer_transform = create_vector_transform(\n",
    "    2, 5,\n",
    "    linear_transform_type=\"permutation\",\n",
    "    base_transform_type=\"affine-coupling\",\n",
    "    context_features=None,\n",
    "    hidden_features=100,\n",
    "    num_transform_blocks=1,\n",
    ")\n",
    "inner_transform=transforms.ConditionalAffineScalarTransform(features=1)\n",
    "\n",
    "pie = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    outer_transform=outer_transform,\n",
    "    inner_transform=inner_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    trainer = training.trainer.ManifoldFlowTrainer(pie)\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.nll],\n",
    "        loss_weights=[1.],\n",
    "        epochs=epochs,\n",
    "        forward_kwargs={\"mode\":\"pie\"}\n",
    "    )\n",
    "    torch.save(pie.state_dict(), \"../data/models/pie_1_spherical_gaussian_1_2_0.010.pt\")\n",
    "else:\n",
    "    pie.load_state_dict(torch.load(\"../data/models/pie_1_spherical_gaussian_1_2_0.010.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice of PIE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_transform = create_vector_transform(\n",
    "    2, 5,\n",
    "    linear_transform_type=\"permutation\",\n",
    "    base_transform_type=\"affine-coupling\",\n",
    "    context_features=None,\n",
    "    hidden_features=100,\n",
    "    num_transform_blocks=1,\n",
    ")\n",
    "inner_transform=transforms.ConditionalAffineScalarTransform(features=1)\n",
    "\n",
    "slice_of_pie = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    outer_transform=outer_transform,\n",
    "    inner_transform=inner_transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    trainer = training.trainer.ManifoldFlowTrainer(slice_of_pie)\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.mse],\n",
    "        loss_weights=[100.],\n",
    "        epochs=epochs // 3,\n",
    "        forward_kwargs={\"mode\": \"projection\"}\n",
    "    )\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.mse, training.losses.nll],\n",
    "        loss_weights=[100., 0.1],\n",
    "        epochs=epochs // 3,\n",
    "        forward_kwargs={\"mode\": \"slice\"}\n",
    "    )\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.mse, training.losses.nll],\n",
    "        loss_weights=[0., 1.],\n",
    "        epochs=epochs // 3,\n",
    "        parameters=mf.inner_transform.parameters(),\n",
    "        forward_kwargs={\"mode\": \"slice\"}\n",
    "    )\n",
    "    torch.save(slice_of_pie.state_dict(), \"../data/models/slice_1_spherical_gaussian_1_2_0.010.pt\")\n",
    "else:\n",
    "    slice_of_pie.load_state_dict(torch.load(\"../data/models/slice_1_spherical_gaussian_1_2_0.010.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure GAMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_transform = create_vector_transform(\n",
    "    2, 5,\n",
    "    linear_transform_type=\"permutation\",\n",
    "    base_transform_type=\"affine-coupling\",\n",
    "    context_features=None,\n",
    "    hidden_features=100,\n",
    "    num_transform_blocks=1,\n",
    "    resnet_transform=False,\n",
    ")\n",
    "inner_transform=transforms.ConditionalAffineScalarTransform(features=1)\n",
    "\n",
    "gamf = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    inner_transform=inner_transform,\n",
    "    outer_transform=outer_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if train:\n",
    "    ftrainer = training.trainer.ManifoldFlowTrainer(gamf)\n",
    "    ftrainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.mse],\n",
    "        loss_weights=[100.],\n",
    "        epochs=epochs // 4,\n",
    "        forward_kwargs={\"mode\":\"projection\"}\n",
    "    )\n",
    "    gtrainer = training.trainer.GenerativeTrainer(gamf)\n",
    "    gtrainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.make_sinkhorn_divergence()],\n",
    "        loss_weights=[100.],\n",
    "        epochs=epochs * 3 // 4,\n",
    "        batch_size=1000,\n",
    "    )\n",
    "    torch.save(gamf.state_dict(), \"../data/models/gamf_1_spherical_gaussian_1_2_0.010.pt\")\n",
    "else:\n",
    "    gamf.load_state_dict(torch.load(\"../data/models/gamf_1_spherical_gaussian_1_2_0.010.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_transform = create_vector_transform(\n",
    "    2, 5,\n",
    "    linear_transform_type=\"permutation\",\n",
    "    base_transform_type=\"affine-coupling\",\n",
    "    context_features=None,\n",
    "    hidden_features=100,\n",
    "    num_transform_blocks=1,\n",
    "    resnet_transform=False,\n",
    ")\n",
    "inner_transform=transforms.ConditionalAffineScalarTransform(features=1)\n",
    "\n",
    "hybrid = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    inner_transform=inner_transform,\n",
    "    outer_transform=outer_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    ftrainer = training.trainer.ManifoldFlowTrainer(hybrid)\n",
    "    ftrainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.mse],\n",
    "        loss_weights=[100.],\n",
    "        epochs=epochs // 4,\n",
    "        forward_kwargs={\"mode\":\"projection\"}\n",
    "    )\n",
    "    gtrainer = training.trainer.GenerativeTrainer(hybrid)\n",
    "    gtrainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.make_sinkhorn_divergence()],\n",
    "        loss_weights=[100.],\n",
    "        epochs=epochs // 4,\n",
    "        batch_size=1000,\n",
    "    )\n",
    "    ftrainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.mse, training.losses.nll],\n",
    "        loss_weights=[100., 0.1],\n",
    "        epochs=epochs // 4,\n",
    "        forward_kwargs={\"mode\":\"mf\"}\n",
    "    )\n",
    "    ftrainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.mse, training.losses.nll],\n",
    "        loss_weights=[0., 1.],\n",
    "        epochs=epochs // 4,\n",
    "        parameters=mf.inner_transform.parameters(),\n",
    "        forward_kwargs={\"mode\":\"mf\"}\n",
    "    )\n",
    "    torch.save(hybrid.state_dict(), \"../data/models/hybrid_1_spherical_gaussian_1_2_0.010.pt\")\n",
    "else:\n",
    "    hybrid.load_state_dict(torch.load(\"../data/models/hybrid_1_spherical_gaussian_1_2_0.010.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = create_vector_transform(\n",
    "    2, 5,\n",
    "    linear_transform_type=\"permutation\",\n",
    "    base_transform_type=\"affine-coupling\",\n",
    "    context_features=None,\n",
    "    hidden_features=100,\n",
    "    num_transform_blocks=1,\n",
    ")\n",
    "sf = Flow(\n",
    "    data_dim=2,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train:\n",
    "    trainer = training.trainer.ManifoldFlowTrainer(sf)\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.nll],\n",
    "        loss_weights=[1.],\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    torch.save(sf.state_dict(), \"../data/models/flow_1_spherical_gaussian_1_2_0.010.pt\")\n",
    "else:\n",
    "    sf.load_state_dict(torch.load(\"../data/models/flow_1_spherical_gaussian_1_2_0.010.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifold flow with specified manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_transform=transforms.SphericalCoordinates(dim=1, r0=1.)\n",
    "inner_transform=transforms.ConditionalAffineScalarTransform(features=1)\n",
    "\n",
    "smf = ManifoldFlow(\n",
    "    data_dim=2,\n",
    "    latent_dim=1,\n",
    "    inner_transform=inner_transform,\n",
    "    outer_transform=outer_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    trainer = training.trainer.ManifoldFlowTrainer(smf)\n",
    "    trainer.train(\n",
    "        train_dataset,\n",
    "        [training.losses.nll],\n",
    "        loss_weights=[1.],\n",
    "        epochs=epochs,\n",
    "        forward_kwargs={\"mode\":\"mf\"}\n",
    "    )\n",
    "    torch.save(smf.state_dict(), \"../data/models/smf_1_spherical_gaussian_1_2_0.010.pt\")\n",
    "else:\n",
    "    smf.load_state_dict(torch.load(\"../data/models/smf_1_spherical_gaussian_1_2_0.010.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the generative performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gen_sf = sf.sample(n=1000).detach().numpy()\n",
    "x_gen_mf = mf.sample(n=1000).detach().numpy()\n",
    "x_gen_pie = pie.sample(n=1000).detach().numpy()\n",
    "x_gen_pie_full = pie.sample(n=1000, sample_orthogonal=True).detach().numpy()\n",
    "x_gen_gamf = gamf.sample(n=1000).detach().numpy()\n",
    "x_gen_hybrid = hybrid.sample(n=1000).detach().numpy()\n",
    "x_gen_smf = smf.sample(n=1000).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance from manifold, true likelihood of generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generative_metrics(x_gen, logp_min=-100., d_max=1., summary_fn=np.mean):\n",
    "    logp_gen = simulator.log_density(x_gen)\n",
    "    logp_gen[(~np.isfinite(logp_gen)) + (logp_gen<logp_min)] = logp_min\n",
    "    logp_summary = summary_fn(logp_gen)\n",
    "    \n",
    "    d_gen = np.abs(np.sum(x_gen**2, axis=1)**0.5 - 1)\n",
    "    d_gen[(~np.isfinite(d_gen)) + (d_gen>d_max)] = d_max\n",
    "    d_summary = summary_fn(d_gen)\n",
    "    \n",
    "    return logp_summary, d_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logp_gen_sf, d_gen_sf = generative_metrics(x_gen_sf)\n",
    "logp_gen_mf, d_gen_mf = generative_metrics(x_gen_mf)\n",
    "logp_gen_pie, d_gen_pie = generative_metrics(x_gen_pie)\n",
    "logp_gen_pie_full, d_gen_pie_full = generative_metrics(x_gen_pie_full)\n",
    "logp_gen_gamf, d_gen_gamf = generative_metrics(x_gen_gamf)\n",
    "logp_gen_hybrid, d_gen_hybrid = generative_metrics(x_gen_gamf)\n",
    "logp_gen_smf, d_gen_smf = generative_metrics(x_gen_smf)\n",
    "\n",
    "print(\"Mean true log likelihood of samples generated from flows (higher is better):\")\n",
    "print(\"  Standard flow:      {:>6.1f}\".format(logp_gen_sf))\n",
    "print(\"  PIE (sampling all): {:>6.1f}\".format(logp_gen_pie_full))\n",
    "print(\"  PIE (sampling M):   {:>6.1f}\".format(logp_gen_pie))\n",
    "print(\"  Manifold flow:      {:>6.1f}\".format(logp_gen_mf))\n",
    "print(\"  Specified MF:       {:>6.1f}\".format(logp_gen_smf))\n",
    "print(\"  Gen. adv. MF:       {:>6.1f}\".format(logp_gen_gamf))\n",
    "print(\"  MF/GAMF hybrid:     {:>6.1f}\".format(logp_gen_hybrid))\n",
    "\n",
    "print(\"Mean Euclidean distance between samples generated from flows and true manifold (lower is better):\")\n",
    "print(\"  Standard flow:      {:>6.4f}\".format(d_gen_sf))\n",
    "print(\"  PIE (sampling all): {:>6.4f}\".format(d_gen_pie))\n",
    "print(\"  PIE (sampling M):   {:>6.4f}\".format(d_gen_pie))\n",
    "print(\"  Manifold flow:      {:>6.4f}\".format(d_gen_mf))\n",
    "print(\"  Specified MF:       {:>6.4f}\".format(d_gen_smf))\n",
    "print(\"  Gen. adv. MF:       {:>6.4f}\".format(d_gen_gamf))\n",
    "print(\"  MF/GAMF hybrid:     {:>6.4f}\".format(d_gen_hybrid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip = 4\n",
    "res = 250\n",
    "x_range = np.linspace(-1.5,1.5,res)\n",
    "y_range = np.linspace(-1.5,1.5,res)\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "x_grid = np.concatenate((xx.reshape((-1,1)), yy.reshape((-1,1))), axis=1)\n",
    "logp_grid = simulator.log_density(x_grid).reshape((res, res))\n",
    "logp_grid[~np.isfinite(logp_grid)] = -1000000.\n",
    "zmin, zmax = np.max(logp_grid) - 10., np.max(logp_grid)+ 10.\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "\n",
    "for i, (label, x) in enumerate(zip(\n",
    "    [\"Standard flow\", \"PIE\", \"Manifold flow\", \"Specified MF\",  \"Generative adversarial MF\", \"Hybrid\"],\n",
    "    [x_gen_sf, x_gen_pie_full, x_gen_mf, x_gen_smf, x_gen_gamf, x_gen_hybrid]\n",
    "     )):\n",
    "    ax = plt.subplot(2,3,i+1)\n",
    "\n",
    "    pcm = plt.imshow(\n",
    "        np.clip(logp_grid, zmin, zmax),\n",
    "        extent=(-1.5,1.5,-1.5,1.5),\n",
    "        origin=\"lower\",\n",
    "        cmap=\"Greys\",\n",
    "        norm=matplotlib.colors.Normalize(zmin, zmax),\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "    cb = plt.colorbar(pcm, extend=\"both\")\n",
    "    plt.scatter(x[::skip,0], x[::skip,1], s=12., c=\"C3\", label=label)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.xlim(-1.5, 1.5)\n",
    "    plt.ylim(-1.5, 1.5)\n",
    "    plt.xlabel(\"$x_1$\")\n",
    "    plt.ylabel(\"$x_2$\")\n",
    "    cb.set_label(\"True log density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/spherical_gaussian_2d_generation.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize learned likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate log likelihood on grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 200\n",
    "x_range = np.linspace(-1.5,1.5,res)\n",
    "y_range = np.linspace(-1.5,1.5,res)\n",
    "xx, yy = np.meshgrid(x_range, y_range)\n",
    "x_grid = np.concatenate((xx.reshape((-1,1)), yy.reshape((-1,1))), axis=1)\n",
    "x_grid_tensor = torch.FloatTensor(x_grid)\n",
    "\n",
    "learned_logp_grid_sf = sf.log_prob(x_grid_tensor).detach().numpy().reshape((res, res))\n",
    "learned_logp_grid_pie = pie.log_prob(x_grid_tensor, mode=\"pie\").detach().numpy().reshape((res, res))\n",
    "\n",
    "# learned_logp_grid_mf = mf.log_prob(x_grid_tensor, mode=\"mf\").detach().numpy().reshape((res, res))\n",
    "# learned_logp_grid_slice_of_pie = slice_of_pie.log_prob(x_grid_tensor, mode=\"slice\").detach().numpy().reshape((res, res))\n",
    "\n",
    "logp_grid_truth = simulator.log_density(x_grid).reshape((res, res))\n",
    "logp_grid_truth[~np.isfinite(logp_grid_truth)] = -1000000.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate along manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood_along_manifold(model, mode, zmin=-5., zmax=5., n_samples=100, epsilon=0.02):\n",
    "    # Sample\n",
    "    u = torch.linspace(zmin, zmax, n_samples).view(-1,1)\n",
    "    x = model.sample(n=n_samples, u=u).detach().numpy()\n",
    "    \n",
    "    # Interpolate\n",
    "    x_interpol = [x[0]]\n",
    "    for x, x_prev in zip(x[:-1], x[1:]):\n",
    "        distance = np.linalg.norm(x-x_prev)\n",
    "        if distance > epsilon:\n",
    "            n_insert = int(distance / epsilon)\n",
    "            for frac in np.linspace(0., 1., n_insert + 2)[1:-1]:\n",
    "                x_interpol.append(x_prev + frac * (x-x_prev))\n",
    "        x_interpol.append(x)\n",
    "    x_interpol.append(x)\n",
    "    x_interpol = np.array(x_interpol)\n",
    "    print(x_interpol.shape)\n",
    "\n",
    "    # Evaluate likelihood\n",
    "    log_probs = model.log_prob(torch.FloatTensor(x_interpol), mode=mode).detach().numpy()\n",
    "\n",
    "    # Return\n",
    "    return x_interpol, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_manifold_mf, learned_logp_manifold_mf = likelihood_along_manifold(mf, \"mf\")\n",
    "x_manifold_slice, learned_logp_manifold_slice = likelihood_along_manifold(slice_of_pie, \"slice\")\n",
    "x_manifold_gamf, learned_logp_manifold_gamf = likelihood_along_manifold(gamf, \"mf\")\n",
    "x_manifold_hybrid, learned_logp_manifold_hybrid = likelihood_along_manifold(hybrid, \"mf\")\n",
    "x_manifold_smf, learned_logp_manifold_smf = likelihood_along_manifold(smf, \"smf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,12))\n",
    "\n",
    "for i, (label, logp, x) in enumerate(zip(\n",
    "    [\"simulator\", \"standard flow\", \"PIE\",\n",
    "     \"slice of PIE\", \"manifold flow\", \"specified MF\",\n",
    "     \"generative adversarial MF\", \"hybrid\"],\n",
    "    [logp_grid_truth, learned_logp_grid_sf, learned_logp_grid_pie,\n",
    "     learned_logp_manifold_slice, learned_logp_manifold_mf, learned_logp_manifold_smf,\n",
    "     learned_logp_manifold_gamf, learned_logp_manifold_hybrid],\n",
    "    [None, None, None,\n",
    "     x_manifold_slice, x_manifold_mf, x_manifold_smf,\n",
    "     x_manifold_gamf, x_manifold_hybrid]\n",
    "     )):\n",
    "    ax = plt.subplot(3,3,i+1)\n",
    "\n",
    "    zmin, zmax = np.max(logp) - 5., np.max(logp)\n",
    "\n",
    "    if x is None:\n",
    "        pcm = plt.imshow(\n",
    "            np.clip(logp, zmin, zmax),\n",
    "            extent=(-1.5, 1.5, -1.5, 1.5),\n",
    "            origin=\"lower\",\n",
    "            cmap=\"viridis\",\n",
    "            norm=matplotlib.colors.Normalize(zmin, zmax),\n",
    "            interpolation='nearest'\n",
    "        )\n",
    "    else:\n",
    "        pcm = plt.scatter(\n",
    "            x[:,0], x[:,1],\n",
    "            c=np.clip(logp, zmin, zmax),\n",
    "            s=15.,\n",
    "            cmap=\"viridis\",\n",
    "            norm=matplotlib.colors.Normalize(zmin, zmax),\n",
    "        )\n",
    "    cb = plt.colorbar(pcm, extend=\"both\")\n",
    "\n",
    "    plt.xlim(-1.5,1.5)\n",
    "    plt.ylim(-1.5,1.5)\n",
    "    plt.xlabel(\"$x_1$\")\n",
    "    plt.ylabel(\"$x_2$\")\n",
    "    cb.set_label(\"log prob, \" + label)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/spherical_gaussian_2d_log_prob.pdf\", dpi=600)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot reconstruction performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = SphericalGaussianSimulator(1,2,epsilon=10*epsilon).sample(100)\n",
    "x_in = torch.FloatTensor(x_in)\n",
    "x_out = mf(x_in)[0]\n",
    "x_in, x_out = x_in.detach().numpy(), x_out.detach().numpy()\n",
    "dx = x_out - x_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.gca()\n",
    "plt.scatter(x_in[:,0], x_in[:,1], s=15., c=\"C1\")\n",
    "plt.scatter(x_out[:,0], x_out[:,1], s=15., c=\"C0\")\n",
    "plt.quiver(\n",
    "    x_in[:,0], x_in[:,1], dx[:,0], dx[:,1],\n",
    "    angles='xy', scale_units='xy', scale=1., width=2.e-3, alpha=1.\n",
    ")\n",
    "\n",
    "plt.xlim(-1.5,1.5)\n",
    "plt.ylim(-1.5,1.5)\n",
    "plt.xlabel(\"$x_1$\")\n",
    "plt.ylabel(\"$x_2$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../figures/spherical_gaussian_2d_mf_reco.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model anatomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_anatomy_plot(model, name, res=25):\n",
    "    x_range = np.linspace(-1.5,1.5,res)\n",
    "    y_range = np.linspace(-1.5,1.5,res)\n",
    "    xx, yy = np.meshgrid(x_range, y_range)\n",
    "    x = np.concatenate((xx.reshape((-1,1)), yy.reshape((-1,1))), axis=1)\n",
    "    x = torch.FloatTensor(x)\n",
    "    x.requires_grad = True\n",
    "\n",
    "    # Encode\n",
    "    u, h_manifold, h_orthogonal, log_det_outer, log_det_inner = model._encode(x)\n",
    "\n",
    "    # Decode\n",
    "    x_reco, _, _, inv_jacobian_outer = model._decode(u, mode=\"mf\")\n",
    "    _, inv_log_det_inner, inv_log_det_outer, _ = model._decode(u, mode=\"slice\")\n",
    "\n",
    "    # inv_jacobian_outer is dx / du, but still need to restrict this to the manifold latents\n",
    "    inv_jacobian_outer = inv_jacobian_outer[:, :, : model.latent_dim]\n",
    "    # And finally calculate log det (J^T J)\n",
    "    jtj = torch.bmm(torch.transpose(inv_jacobian_outer, -2, -1), inv_jacobian_outer)\n",
    "    mf_log_det_outer = - 0.5 * torch.slogdet(jtj)[1]\n",
    "\n",
    "    # Base log prob\n",
    "    log_prob_latent = model.manifold_latent_distribution._log_prob(u, context=None)\n",
    "    \n",
    "    # Plot\n",
    "    fig = plt.figure(figsize=(12,9))\n",
    "\n",
    "    for panel, (label, quantity, diverging) in enumerate(zip(\n",
    "        [\"Perp latent\", \"Manifold latent after outer flow\", \"Manifold latent after inner flow\",\n",
    "         \"log det outer (PIE)\", \"log det inner\", \"Base log prob\",\n",
    "         \"log det outer (MF)\", \"log det outer (Slice of PIE)\", \"delta log det outer (MF - Slice)\"],\n",
    "        [h_orthogonal, h_manifold, u,\n",
    "         log_det_outer, - log_det_inner, log_prob_latent,\n",
    "         mf_log_det_outer, - inv_log_det_outer, mf_log_det_outer + inv_log_det_outer],\n",
    "        [True, True, True, False, False, False, False, False, False]\n",
    "    )):\n",
    "        ax = plt.subplot(3,3,panel+1)\n",
    "\n",
    "        quantity_ = quantity.detach().numpy()\n",
    "        quantity_ = quantity_.flatten() + np.zeros((res**2))\n",
    "\n",
    "        if diverging:\n",
    "            zmin, zmax = - 2. * np.std(quantity_), 2. * np.std(quantity_)\n",
    "        else:\n",
    "            zmin, zmax = np.mean(quantity_) - 1.5 * np.std(quantity_), np.mean(quantity_) + 1.5 * np.std(quantity_)\n",
    "\n",
    "        pcm = plt.imshow(\n",
    "            np.clip(quantity_, zmin, zmax).reshape(res, res),\n",
    "            extent=(-1.5, 1.5, -1.5, 1.5),\n",
    "            origin=\"lower\",\n",
    "            cmap=\"PRGn\" if diverging else \"viridis\",\n",
    "            norm=matplotlib.colors.Normalize(zmin, zmax),\n",
    "            interpolation='nearest'\n",
    "        )\n",
    "        cb = plt.colorbar(pcm, extend=\"both\")\n",
    "        # plt.scatter(x_gen_mf[::10,0], x_gen_mf[::10,1], s=3., c=\"black\")\n",
    "\n",
    "        plt.xlim(-1.5,1.5)\n",
    "        plt.ylim(-1.5,1.5)\n",
    "        plt.xlabel(\"$x_1$\")\n",
    "        plt.ylabel(\"$x_2$\")\n",
    "        cb.set_label(label)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"../figures/spherical_gaussian_2d_{}_anatomy.pdf\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_anatomy_plot(mf, \"mf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_anatomy_plot(slice_of_pie, \"slice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_anatomy_plot(pie, \"pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_anatomy_plot(gamf, \"gamf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_anatomy_plot(hybrid, \"hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_anatomy_plot(smf, \"smf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
