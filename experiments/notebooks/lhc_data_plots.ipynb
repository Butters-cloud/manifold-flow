{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore LHC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import corner\n",
    "import logging\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import OPTICS, DBSCAN\n",
    "import numpy as np\n",
    "from ripser import ripser\n",
    "from persim import plot_diagrams\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)-5.5s %(name)-30.30s %(levelname)-7.7s %(message)s\",\n",
    "    datefmt=\"%H:%M\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from experiments.datasets import WBFLoader, WBF40DLoader\n",
    "import plot_settings as ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = WBFLoader()\n",
    "sim40d = WBF40DLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:51 experiments.datasets.collider  INFO    Only using 10000 of 1000000 available samples\n",
      "17:51 experiments.datasets.collider  INFO    Only using 10000 of 1000000 available samples\n",
      "17:51 experiments.datasets.collider  INFO    Only using 10000 of 10000 available samples\n",
      "17:51 experiments.datasets.collider  INFO    Only using 10000 of 10000 available samples\n"
     ]
    }
   ],
   "source": [
    "x, params = sim.load_dataset(train=True, dataset_dir=\"../data/samples/lhc\", numpy=True, limit_samplesize=n)\n",
    "x_ = sim._preprocess(x, inverse=True)\n",
    "x_noise = np.random.normal(size=x.shape)\n",
    "\n",
    "x40d, _ = sim40d.load_dataset(train=True, dataset_dir=\"../data/samples/lhc40d\", numpy=True, limit_samplesize=n)\n",
    "x40d_noise = np.random.normal(size=x40d.shape)\n",
    "x40d_test, _ = sim40d.load_dataset(train=False, dataset_dir=\"../data/samples/lhc40d\", numpy=True, limit_samplesize=n)\n",
    "x40d_test2, _ = sim40d.load_dataset(train=False, dataset_dir=\"../data/samples/lhc40d\", numpy=True, limit_samplesize=n, true_param_id=2)\n",
    "x40d_mfmf = np.load(\"../data/results/mf_14_lhc40d_sequential_scandal_may_samples.npy\")\n",
    "x40d_mfmf2 = np.load(\"../data/results/mf_14_lhc40d_sequential_scandal_may_samples_trueparam2.npy\")\n",
    "x40d_af = np.load(\"../data/results/flow_14_lhc40d_scandal_may_samples.npy\")\n",
    "x40d_af2 = np.load(\"../data/results/flow_14_lhc40d_scandal_may_samples_trueparam2.npy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=48)\n",
    "pca.fit(x)\n",
    "\n",
    "explained_var = pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(np.arange(1, 48.5), explained_var, ls=\" \", marker=\"o\", ms=5.)\n",
    "\n",
    "plt.ylim(0.,None)\n",
    "plt.xlabel(\"PCA component\")\n",
    "plt.ylabel(\"Explained variance ratio\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=1000).fit_transform(x40d)\n",
    "noise_tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=1000).fit_transform(x40d_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_reshuffled = np.copy(x40d)\n",
    "idx = np.random.rand(*x_reshuffled.shape).argsort(0)\n",
    "x_reshuffled = x_reshuffled[idx, np.arange(x_reshuffled.shape[1])]\n",
    "\n",
    "x_reshuffled_tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=1000).fit_transform(x_reshuffled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "ax = plt.subplot(1,3,1)\n",
    "plt.scatter(\n",
    "    x_tsne[:, 0],\n",
    "    x_tsne[:, 1],\n",
    "    s=12.0,\n",
    "    alpha=0.15,\n",
    "    c=\"C0\"\n",
    ")\n",
    "# plt.scatter(\n",
    "#     x_tsne[x40d[:,16]>0.][:, 0],\n",
    "#     x_tsne[x40d[:,16]>0.][:, 1],\n",
    "#     s=12.0,\n",
    "#     alpha=0.15,\n",
    "#     c=\"C0\"\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     x_tsne[x40d[:,16]<0.][:, 0],\n",
    "#     x_tsne[x40d[:,16]<0.][:, 1],\n",
    "#     s=12.0,\n",
    "#     alpha=0.15,\n",
    "#     c=\"C1\"\n",
    "# )\n",
    "plt.xlabel(\"t-SNE component 0\")\n",
    "plt.ylabel(\"t-SNE component 1\")\n",
    "\n",
    "ax = plt.subplot(1,3,2)\n",
    "plt.scatter(\n",
    "    x_reshuffled_tsne[:, 0],\n",
    "    x_reshuffled_tsne[:, 1],\n",
    "    s=12.0,\n",
    "    alpha=0.15,\n",
    "    c=\"C2\"\n",
    ")\n",
    "plt.xlabel(\"t-SNE component 0\")\n",
    "plt.ylabel(\"t-SNE component 1\")\n",
    "\n",
    "ax = plt.subplot(1,3,3)\n",
    "plt.scatter(\n",
    "    noise_tsne[:, 0],\n",
    "    noise_tsne[:, 1],\n",
    "    s=12.0,\n",
    "    alpha=0.15,\n",
    "    c=\"C4\"\n",
    ")\n",
    "plt.xlabel(\"t-SNE component 0\")\n",
    "plt.ylabel(\"t-SNE component 1\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/lhc_tsne.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npanels = 40\n",
    "ncols = 6\n",
    "nrows = (npanels - 1) // ncols + 1\n",
    "\n",
    "plt.figure(figsize=(ncols * 3, nrows * 3))\n",
    "\n",
    "for i in range(npanels):\n",
    "    ax = plt.subplot(nrows,ncols,i+1)\n",
    "    plt.scatter(\n",
    "        x_tsne[x40d[:,i]>0.][:250, 0],\n",
    "        x_tsne[x40d[:,i]>0.][:250, 1],\n",
    "        s=12.0,\n",
    "        c=\"C0\"\n",
    "    )\n",
    "    plt.scatter(\n",
    "        x_tsne[x40d[:,i]<0.][:250, 0],\n",
    "        x_tsne[x40d[:,i]<0.][:250, 1],\n",
    "        s=12.0,\n",
    "        c=\"C1\"\n",
    "    )\n",
    "    plt.title(\"Feature {}\".format(i))\n",
    "    plt.xlabel(\"t-SNE 0\")\n",
    "    plt.ylabel(\"t-SNE 1\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/lhc_tsne_features.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPTICS and DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(x40d, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering = OPTICS(eps=1., min_samples=5).fit(x)\n",
    "\n",
    "epsilons = [0.1, 0.2, 0.5, 1., 2., 5., 10., 20., 50., 100.]\n",
    "clusterings = [DBSCAN(eps=eps, min_samples=5).fit(x40d) for eps in epsilons]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_fracs = [np.array([np.sum(cl.labels_ == i) for cl in clusterings]) / len(x40d) for i in [0, 1, 2, 3, 4, -1]]\n",
    "labels = [f\"Cluster {i+1}\" for i in range(5)] + [\"Noise\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "for cluster_frac, label in zip(cluster_fracs, labels):\n",
    "    if \"Noise\" in label:\n",
    "        plt.plot(epsilons, cluster_frac, label=label, c=\"0.6\", ls=\"--\")\n",
    "    else:\n",
    "        plt.plot(epsilons, cluster_frac, label=label)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylim(0., 1.05)\n",
    "plt.xscale(\"log\")\n",
    "\n",
    "plt.xlabel(r\"$\\epsilon$\")\n",
    "plt.ylabel(\"Fraction of samples\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/lhc_dbscan.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDA: persistent cohomology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mripser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmaxdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mthresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcoeff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdistance_matrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdo_cocycles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'euclidean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_perm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Compute persistence diagrams for X data array. If X is not a distance matrix, it will be converted to a distance matrix using the chosen metric.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "X: ndarray (n_samples, n_features)\n",
       "    A numpy array of either data or distance matrix.\n",
       "    Can also be a sparse distance matrix of type scipy.sparse\n",
       "\n",
       "maxdim: int, optional, default 1\n",
       "    Maximum homology dimension computed. Will compute all dimensions \n",
       "    lower than and equal to this value. \n",
       "    For 1, H_0 and H_1 will be computed.\n",
       "\n",
       "thresh: float, default infinity\n",
       "    Maximum distances considered when constructing filtration. \n",
       "    If infinity, compute the entire filtration.\n",
       "\n",
       "coeff: int prime, default 2\n",
       "    Compute homology with coefficients in the prime field Z/pZ for p=coeff.\n",
       "\n",
       "distance_matrix: bool\n",
       "    Indicator that X is a distance matrix, if not we compute a \n",
       "    distance matrix from X using the chosen metric.\n",
       "\n",
       "do_cocycles: bool\n",
       "    Indicator of whether to compute cocycles, if so, we compute and store\n",
       "    cocycles in the `cocycles_` dictionary Rips member variable\n",
       "\n",
       "metric: string or callable\n",
       "    The metric to use when calculating distance between instances in a \n",
       "    feature array. If metric is a string, it must be one of the options \n",
       "    specified in pairwise_distances, including \"euclidean\", \"manhattan\", \n",
       "    or \"cosine\". Alternatively, if metric is a callable function, it is \n",
       "    called on each pair of instances (rows) and the resulting value \n",
       "    recorded. The callable should take two arrays from X as input and \n",
       "    return a value indicating the distance between them.\n",
       "\n",
       "n_perm: int\n",
       "    The number of points to subsample in a \"greedy permutation,\"\n",
       "    or a furthest point sampling of the points.  These points\n",
       "    will be used in lieu of the full point cloud for a faster\n",
       "    computation, at the expense of some accuracy, which can \n",
       "    be bounded as a maximum bottleneck distance to all diagrams\n",
       "    on the original point set\n",
       "\n",
       "Returns\n",
       "-------\n",
       "A dictionary holding all of the results of the computation\n",
       "\n",
       "{'dgms': list (size maxdim) of ndarray (n_pairs, 2)\n",
       "    A list of persistence diagrams, one for each dimension less \n",
       "    than maxdim. Each diagram is an ndarray of size (n_pairs, 2) \n",
       "    with the first column representing the birth time and the \n",
       "    second column representing the death time of each pair.\n",
       " 'cocycles': list (size maxdim) of list of ndarray\n",
       "    A list of representative cocycles in each dimension.  The list \n",
       "    in each dimension is parallel to the diagram in that dimension;\n",
       "    that is, each entry of the list is a representative cocycle of\n",
       "    the corresponding point expressed as an ndarray(K, d+1), where K is\n",
       "    the number of nonzero values of the cocycle and d is the dimension\n",
       "    of the cocycle.  The first d columns of each array index into\n",
       "    the simplices of the (subsampled) point cloud, and the last column\n",
       "    is the value of the cocycle at that simplex\n",
       " 'num_edges': int\n",
       "    The number of edges added during the computation\n",
       " 'dperm2all': ndarray(n_samples, n_samples) or ndarray (n_perm, n_samples) if n_perm\n",
       "    The distance matrix used in the computation if n_perm is none.\n",
       "    Otherwise, the distance from all points in the permutation to\n",
       "    all points in the dataset\n",
       " 'idx_perm': ndarray(n_perm) if n_perm > 0\n",
       "    Index into the original point cloud of the points used\n",
       "    as a subsample in the greedy permutation\n",
       " 'r_cover': float\n",
       "    Covering radius of the subsampled points.  \n",
       "    If n_perm <= 0, then the full point cloud was used and this is 0\n",
       "}\n",
       "\n",
       "Examples\n",
       "--------\n",
       ".. code:: python\n",
       "\n",
       "    from ripser import ripser, plot_dgms\n",
       "    from sklearn import datasets\n",
       "\n",
       "    data = datasets.make_circles(n_samples=110)[0]\n",
       "    dgms = ripser(data)['dgms']\n",
       "    plot_dgms(dgms)\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/ml/lib/python3.6/site-packages/ripser/ripser.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ripser?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagrams48d = ripser(x, maxdim=2)['dgms']\n",
    "plot_diagrams(diagrams48d, show=False)\n",
    "plt.savefig(\"../figures/lhc_persistent_homology_48d.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagrams = ripser(x40d, maxdim=2)['dgms']\n",
    "plot_diagrams(diagrams, show=False)\n",
    "plt.savefig(\"../figures/lhc_persistent_homology.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine weights for individual closure tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_closure_tests = np.mean(sim._closure_tests(x_noise), axis=1)\n",
    "CLOSURE_TEST_WEIGHTS = 1. / random_closure_tests\n",
    "print(\", \".join([str(w) for w in CLOSURE_TEST_WEIGHTS]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closure test vs noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sim.distance_from_manifold(x)), np.mean(sim.distance_from_manifold(x_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(sim40d.distance_from_manifold(x40d)), np.mean(sim40d.distance_from_manifold(x40d_noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noises = np.geomspace(1.e-9, 1., 100)\n",
    "\n",
    "closure = []\n",
    "\n",
    "for noise in noises:\n",
    "    closure.append(np.mean(sim.distance_from_manifold(x + noise * np.random.normal(size=x.shape))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(noises, closure)\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.xlabel(\"Noise\")\n",
    "plt.ylabel(\"Mean closure\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/lhc_closure_vs_noise.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 7\n",
    "nrows = 6\n",
    "\n",
    "fig = plt.figure(figsize=(3*ncols, 3*nrows))\n",
    "\n",
    "for i in range(40):\n",
    "    ax = plt.subplot(nrows, ncols, i+1)\n",
    "    plt.hist(x40d[:,i], range=(-5,5), bins=50, density=True, color=\"0.8\")\n",
    "    \n",
    "    plt.hist(\n",
    "        x40d_test[:,i], range=(-5,5), bins=50, density=True,\n",
    "        histtype=\"step\", color=\"black\", ls=\"-\", lw=1.5, label=\"Simulator\"\n",
    "    )\n",
    "    plt.hist(\n",
    "        x40d_af[:,i], range=(-5,5), bins=50, density=True,\n",
    "        histtype=\"step\", color=[ps.COLOR_AF], ls=\"-\", lw=1.5, label=\"AF\"\n",
    "    )\n",
    "    plt.hist(\n",
    "        x40d_mfmf[:,i], range=(-5,5), bins=50, density=True,\n",
    "        histtype=\"step\", color=[ps.COLOR_FLMA], ls=\"-\", lw=1.5, label=\"MFMF\"\n",
    "    )\n",
    "    \n",
    "#     plt.hist(\n",
    "#         x40d_test2[:,i], range=(-5,5), bins=50, density=True,\n",
    "#         histtype=\"step\", color=\"black\", ls=\"--\", lw=1.5\n",
    "#     )\n",
    "#     plt.hist(\n",
    "#         x40d_af2[:,i], range=(-5,5), bins=50, density=True,\n",
    "#         histtype=\"step\", color=[ps.COLOR_AF], ls=\"--\", lw=1.5\n",
    "#     )\n",
    "#     plt.hist(\n",
    "#         x40d_mfmf2[:,i], range=(-5,5), bins=50, density=True,\n",
    "#         histtype=\"step\", color=[ps.COLOR_FLMA], ls=\"--\", lw=1.5\n",
    "#     )\n",
    "    \n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "    \n",
    "    ax.get_xaxis().set_ticks([])\n",
    "    ax.get_yaxis().set_ticks([])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/lhc_features_histos.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatter plots of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(range(40))\n",
    "n = len(features)\n",
    "m = 100\n",
    "\n",
    "fig = plt.figure(figsize=(1*(n-1), 1*(n-1)))\n",
    "for ip, i in enumerate(features[1:]):\n",
    "    for jp in range(ip):\n",
    "        j = features[jp]\n",
    "        ax = plt.subplot(n-1, n-1, ip*(n-1) + jp + 1)\n",
    "        plt.scatter(x40d[:m,j], x40d[:m,i], s=2., c=[\"0.5\"], rasterized=True)\n",
    "        plt.scatter(x40d_test[:m,j], x40d_test[:m,i], s=2., c=[\"black\"], rasterized=True)\n",
    "        plt.scatter(x40d_af[:m,j], x40d_af[:m,i], s=2., c=[ps.COLOR_AF], rasterized=True)\n",
    "        plt.scatter(x40d_mfmf[:m,j], x40d_mfmf[:m,i], s=2., c=[ps.COLOR_FLMA], rasterized=True)\n",
    "        ax.get_xaxis().set_ticks([])\n",
    "        ax.get_yaxis().set_ticks([])\n",
    "        plt.xlim(-2.5,2.5)\n",
    "        plt.ylim(-2.5,2.5)\n",
    "        \n",
    "        if ip == n - 2:\n",
    "            plt.xlabel(str(j))\n",
    "        if jp == 0:\n",
    "            plt.ylabel(str(i))\n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig(\"../figures/lhc_features_scatter.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
